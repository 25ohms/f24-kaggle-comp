{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fjtH2YCI_Kp"
   },
   "source": [
    "Importing modules + training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1731990779041,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "sQxpvQgmIYLp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, linear_model, model_selection, metrics, neighbors, ensemble\n",
    "import numpy as np\n",
    "\n",
    "# your files might be in \"Shared with me\" instead of \"My Drive\", or you could just manually upload to the Colab and remove the \"drive/My Drive/STAT441 Kaggle/\" part entirely\n",
    "df_ed_train = pd.read_csv(\"./module_Education_train_set.csv\")\n",
    "df_hh_train = pd.read_csv(\"./module_HouseholdInfo_train_set.csv\")\n",
    "y_train = pd.read_csv(\"./module_SubjectivePoverty_train_set.csv\")\n",
    "\n",
    "df_ed_test = pd.read_csv(\"./module_Education_test_set.csv\")\n",
    "df_hh_test = pd.read_csv(\"./module_HouseholdInfo_test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDc3XWC_JPXa"
   },
   "source": [
    "Combining DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3270,
     "status": "ok",
     "timestamp": 1731990783948,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "8E5bpnR2JZRW",
    "outputId": "ad5c07ac-d376-414f-c1c6-6080f0a3019d"
   },
   "outputs": [],
   "source": [
    "#adding the 'psu_hh_idcode' column for future merging\n",
    "df_ed_train['psu_hh_idcode'] = ['_'.join([str(int(row['psu'])),str(int(row['hh'])),str(int(row['idcode']))]) for index, row in df_ed_train.iterrows()]\n",
    "df_ed_train.drop(['hh', 'idcode'], axis=1, inplace=True)\n",
    "\n",
    "df_hh_train['psu_hh_idcode'] = ['_'.join([str(int(row['psu'])),str(int(row['hh'])),str(int(row['idcode']))]) for index, row in df_hh_train.iterrows()]\n",
    "df_hh_train.drop(['hh', 'idcode'], axis=1, inplace=True)\n",
    "\n",
    "df_ed_test['psu_hh_idcode'] = ['_'.join([str(int(row['psu'])),str(int(row['hh'])),str(int(row['idcode']))]) for index, row in df_ed_test.iterrows()]\n",
    "df_ed_test.drop(['hh', 'idcode'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df_hh_test['psu_hh_idcode'] = ['_'.join([str(int(row['psu'])),str(int(row['hh'])),str(int(row['idcode']))]) for index, row in df_hh_test.iterrows()]\n",
    "df_hh_test.drop(['hh', 'idcode'], axis=1, inplace=True)\n",
    "\n",
    "# combining the subjective_poverty_n columns into a single column\n",
    "y_train = y_train[y_train['psu_hh_idcode'].isin(df_ed_train['psu_hh_idcode'])]\n",
    "sp_onehot = y_train.drop(columns=['psu_hh_idcode'])\n",
    "y_train['subjective_poverty'] = pd.from_dummies(sp_onehot)\n",
    "y_train['subjective_poverty'] = [int(x[19:]) for x in y_train['subjective_poverty']]\n",
    "y_train.drop(columns=['subjective_poverty_' + str(i) for i in range(1,11)], inplace=True)\n",
    "\n",
    "df_ed_train.set_index('psu_hh_idcode', inplace=True)\n",
    "df_hh_train.set_index('psu_hh_idcode', inplace=True)\n",
    "df_ed_test.set_index('psu_hh_idcode', inplace=True)\n",
    "df_hh_test.set_index('psu_hh_idcode', inplace=True)\n",
    "\n",
    "y_train.set_index('psu_hh_idcode', inplace=True)\n",
    "\n",
    "#MAYBE REMOVE THIS PART:\n",
    "# All other columns in the education test set are almost 99% NA\n",
    "# Theoretically including all the rest of the columns should only give at most a score improvement of ~0.023\n",
    "# since it only applies to 1% of the training data (and just giving every option a 0.1 chance is a log loss of 2.3)\n",
    "##### df_ed_train = df_ed_train[['q01', 'q02', 'q03', 'q04', 'q05', 'q06', 'q07', 'Q08', 'Q11', 'Q14', 'Q17', 'Q18', 'Q19']]\n",
    "df_ed_train['set'] = 'train'\n",
    "##### df_ed_test = df_ed_test[['q01', 'q02', 'q03', 'q04', 'q05', 'q06', 'q07', 'Q08', 'Q11', 'Q14', 'Q17', 'Q18', 'Q19']]\n",
    "df_ed_test['set'] = 'test'\n",
    "\n",
    "# combining training and test sets\n",
    "df_ed = pd.concat([df_ed_train, df_ed_test])\n",
    "df_hh = pd.concat([df_hh_train, df_hh_test])\n",
    "\n",
    "df = df_hh.join(df_ed, lsuffix=\"_hh\", how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_cmTwOwJ5O1"
   },
   "source": [
    "Filling in NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6130,
     "status": "ok",
     "timestamp": 1731982494846,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "tktaSGDDJ85_"
   },
   "outputs": [],
   "source": [
    "###df['q07'].fillna(0) # q07 in education is NA => never went to school => 0 years of preschool\n",
    "\n",
    "\n",
    "def highest_education(index):\n",
    "  row = df_ed.loc[index]\n",
    "  if row['q03'] == 2 or row['q06'] == 0:\n",
    "    return 1 # no education\n",
    "  elif row['q06'] == 1:\n",
    "    return 2 # primary 4/5\n",
    "  elif row['q06'] == 2 and row['q04'] == 1:\n",
    "    return 3 # primary 7/8/9\n",
    "  elif row['q04'] == 2 and row['q06'] < 3:\n",
    "    return 4 # some secondary\n",
    "  elif row['q06'] == 3 and row['q04'] == 2:\n",
    "    return 5 # finished secondary\n",
    "  elif row['q06'] < 4 and row['q04'] in [3,4,5]:\n",
    "    return 6 # some vocational (pretty sure \"Technicum\" is  a type of vocational)\n",
    "  elif row['q06'] in [4,5,6] and row['q04'] < 6:\n",
    "    return 7 # finished vocational\n",
    "  elif row['q06'] < 7 and row['q04'] >= 6:\n",
    "    return 8 # some university\n",
    "  elif row['q06'] in [7,8,9]:\n",
    "    return 9 # finished university\n",
    "  else:\n",
    "    return 10 # Post university\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  if row['q11'] == 1:\n",
    "    mother = '_'.join(index.split('_')[:-1] + [str(int(row['q12']))])\n",
    "    if mother in df_ed.index:\n",
    "        row['q13'] = highest_education(mother)\n",
    "    elif mother in df_ed.index:\n",
    "        row['q13'] = highest_education(mother)\n",
    "    row['q14'] = 1\n",
    "    if mother in df_hh.index:\n",
    "        row['q16'] = df_hh.loc[mother]['q05y']\n",
    "\n",
    "  if row['q17'] == 1:\n",
    "    father = '_'.join(index.split('_')[:-1] + [str(int(row['q18']))])\n",
    "    if father in df_ed.index:\n",
    "        row['q19'] = highest_education(father)\n",
    "    row['q20'] = 1\n",
    "    if father in df_hh.index:\n",
    "        row['q22'] = df_hh.loc[father]['q05y']\n",
    "\n",
    "df.drop(columns=['q12', 'q18'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial NA Percentages:\n",
      "\n",
      "q06_hh:\n",
      "Train NA%: 8.66%\n",
      "Test NA%: 0.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q06_hh\n",
      "1.0    0.599294\n",
      "5.0    0.333043\n",
      "4.0    0.056562\n",
      "2.0    0.008441\n",
      "3.0    0.002661\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q07_hh:\n",
      "Train NA%: 45.78%\n",
      "Test NA%: 13.19%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q07_hh\n",
      "1.0    0.967308\n",
      "2.0    0.032692\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q08:\n",
      "Train NA%: 47.51%\n",
      "Test NA%: 16.79%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q08\n",
      "2.0    0.443400\n",
      "1.0    0.432756\n",
      "3.0    0.053997\n",
      "4.0    0.042654\n",
      "5.0    0.010566\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q13:\n",
      "Train NA%: 45.27%\n",
      "Test NA%: 8.02%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q13\n",
      "2.0    0.377317\n",
      "1.0    0.338621\n",
      "3.0    0.208970\n",
      "5.0    0.033062\n",
      "4.0    0.017717\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q14:\n",
      "Train NA%: 45.27%\n",
      "Test NA%: 8.02%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q14\n",
      "2.0    0.524166\n",
      "1.0    0.475834\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q15:\n",
      "Train NA%: 71.52%\n",
      "Test NA%: 48.35%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q15\n",
      "70.0    0.086975\n",
      "80.0    0.075803\n",
      "75.0    0.054165\n",
      "78.0    0.049074\n",
      "65.0    0.042144\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q16:\n",
      "Train NA%: 73.75%\n",
      "Test NA%: 59.67%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q16\n",
      "70.0    0.069170\n",
      "65.0    0.056239\n",
      "75.0    0.048450\n",
      "60.0    0.046425\n",
      "80.0    0.042530\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q19:\n",
      "Train NA%: 40.83%\n",
      "Test NA%: 4.12%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q19\n",
      "2.0    0.375868\n",
      "1.0    0.310656\n",
      "3.0    0.211323\n",
      "5.0    0.041480\n",
      "4.0    0.023182\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q20:\n",
      "Train NA%: 40.83%\n",
      "Test NA%: 4.12%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q20\n",
      "2.0    0.681778\n",
      "1.0    0.318222\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q21:\n",
      "Train NA%: 59.94%\n",
      "Test NA%: 29.84%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q21\n",
      "70.0    0.077086\n",
      "80.0    0.064877\n",
      "75.0    0.053880\n",
      "72.0    0.042377\n",
      "78.0    0.042276\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q22:\n",
      "Train NA%: 80.88%\n",
      "Test NA%: 74.29%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q22\n",
      "70.0    0.078470\n",
      "60.0    0.047557\n",
      "65.0    0.045396\n",
      "75.0    0.045396\n",
      "80.0    0.043882\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q04:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q04\n",
      "1.0    0.545510\n",
      "2.0    0.268722\n",
      "6.0    0.124868\n",
      "5.0    0.025254\n",
      "4.0    0.015565\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q05:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q05\n",
      "4.0    0.339004\n",
      "8.0    0.316380\n",
      "3.0    0.087776\n",
      "2.0    0.067959\n",
      "1.0    0.050596\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q06:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q06\n",
      "2.0    0.397492\n",
      "3.0    0.254472\n",
      "1.0    0.134865\n",
      "9.0    0.079183\n",
      "0.0    0.068660\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "q07:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "q07\n",
      "0.0    0.524027\n",
      "1.0    0.252894\n",
      "2.0    0.140039\n",
      "3.0    0.073658\n",
      "4.0    0.009383\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q08:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q08\n",
      "2.0    0.755437\n",
      "1.0    0.244563\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q09:\n",
      "Train NA%: 75.16%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q09\n",
      "1.0    0.99265\n",
      "2.0    0.00735\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q10:\n",
      "Train NA%: 99.83%\n",
      "Test NA%: 99.85%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q10\n",
      "2.0     0.560976\n",
      "1.0     0.268293\n",
      "13.0    0.073171\n",
      "4.0     0.048780\n",
      "8.0     0.024390\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q11:\n",
      "Train NA%: 28.82%\n",
      "Test NA%: 3.90%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q11\n",
      "13.0    0.647940\n",
      "2.0     0.242890\n",
      "4.0     0.042948\n",
      "12.0    0.021126\n",
      "1.0     0.020778\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q12:\n",
      "Train NA%: 75.34%\n",
      "Test NA%: 99.18%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q12\n",
      "1.0    0.563843\n",
      "2.0    0.236048\n",
      "6.0    0.161098\n",
      "8.0    0.021131\n",
      "5.0    0.012100\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q13:\n",
      "Train NA%: 75.34%\n",
      "Test NA%: 99.18%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q13\n",
      "2.0    0.184215\n",
      "3.0    0.178617\n",
      "1.0    0.162904\n",
      "4.0    0.098971\n",
      "9.0    0.082716\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q14:\n",
      "Train NA%: 3.99%\n",
      "Test NA%: 2.92%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q14\n",
      "2.0    0.752718\n",
      "1.0    0.247282\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q15:\n",
      "Train NA%: 74.90%\n",
      "Test NA%: 98.88%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q15\n",
      "1.0    0.993617\n",
      "2.0    0.006383\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q16:\n",
      "Train NA%: 99.84%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q16\n",
      "13.0    0.555556\n",
      "2.0     0.277778\n",
      "1.0     0.138889\n",
      "12.0    0.027778\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q17:\n",
      "Train NA%: 29.09%\n",
      "Test NA%: 4.05%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q17\n",
      "13.0    0.661871\n",
      "2.0     0.235496\n",
      "4.0     0.043453\n",
      "12.0    0.016193\n",
      "1.0     0.015727\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q18:\n",
      "Train NA%: 29.09%\n",
      "Test NA%: 4.05%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q18\n",
      "14.0    0.363467\n",
      "18.0    0.283784\n",
      "22.0    0.082421\n",
      "10.0    0.063548\n",
      "15.0    0.048404\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q19:\n",
      "Train NA%: 28.93%\n",
      "Test NA%: 3.97%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q19\n",
      "2.0    0.954894\n",
      "1.0    0.045106\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q20:\n",
      "Train NA%: 96.55%\n",
      "Test NA%: 99.85%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q20\n",
      "2.0    0.740979\n",
      "1.0    0.259021\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q21:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q21\n",
      "1.0    0.615275\n",
      "2.0    0.222163\n",
      "6.0    0.135974\n",
      "5.0    0.012134\n",
      "8.0    0.008744\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q22:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q22\n",
      "1.0    0.182905\n",
      "2.0    0.179515\n",
      "3.0    0.177552\n",
      "8.0    0.083155\n",
      "9.0    0.078694\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q23:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q23\n",
      "1.0    0.967166\n",
      "3.0    0.024625\n",
      "2.0    0.008208\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q24:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q24\n",
      "1.0    0.190935\n",
      "0.0    0.156138\n",
      "2.0    0.089757\n",
      "0.5    0.078694\n",
      "3.0    0.058173\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q25:\n",
      "Train NA%: 95.18%\n",
      "Test NA%: 99.55%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q25\n",
      "2.0    0.698895\n",
      "1.0    0.301105\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q26:\n",
      "Train NA%: 75.11%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q26\n",
      "0.0    0.886404\n",
      "1.0    0.079428\n",
      "2.0    0.015385\n",
      "3.0    0.009302\n",
      "5.0    0.005903\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q27:\n",
      "Train NA%: 75.11%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q27\n",
      "10.0    0.204830\n",
      "15.0    0.158318\n",
      "20.0    0.157961\n",
      "30.0    0.124866\n",
      "5.0     0.114490\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q28:\n",
      "Train NA%: 75.11%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q28\n",
      "1.0    0.776923\n",
      "5.0    0.169767\n",
      "4.0    0.048837\n",
      "2.0    0.002326\n",
      "7.0    0.001252\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q29:\n",
      "Train NA%: 94.53%\n",
      "Test NA%: 99.55%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q29\n",
      "20000.0    0.119415\n",
      "30000.0    0.096669\n",
      "0.0        0.090171\n",
      "12000.0    0.085297\n",
      "10000.0    0.075548\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q30:\n",
      "Train NA%: 94.53%\n",
      "Test NA%: 99.55%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q30\n",
      "2.0    0.977254\n",
      "1.0    0.022746\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q31:\n",
      "Train NA%: 99.88%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q31\n",
      "20000.0     0.214286\n",
      "0.0         0.142857\n",
      "15000.0     0.142857\n",
      "100000.0    0.107143\n",
      "10000.0     0.071429\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q32:\n",
      "Train NA%: 75.11%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q32\n",
      "2.0    0.76458\n",
      "1.0    0.23542\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q33:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q33\n",
      "0.0         0.661967\n",
      "10000.0     0.048988\n",
      "5000.0      0.028380\n",
      "20000.0     0.023138\n",
      "100000.0    0.020246\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q34:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q34\n",
      "0.0        0.708966\n",
      "10000.0    0.068330\n",
      "20000.0    0.043022\n",
      "15000.0    0.035973\n",
      "5000.0     0.023861\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q35:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q35\n",
      "30000.0    0.131598\n",
      "50000.0    0.126537\n",
      "40000.0    0.118040\n",
      "20000.0    0.063268\n",
      "35000.0    0.053868\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q36:\n",
      "Train NA%: 75.38%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q36\n",
      "0.0        0.755515\n",
      "10000.0    0.067812\n",
      "20000.0    0.046112\n",
      "5000.0     0.022242\n",
      "15000.0    0.020434\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q37:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q37\n",
      "10000.0    0.277165\n",
      "0.0        0.171940\n",
      "20000.0    0.128187\n",
      "5000.0     0.103056\n",
      "15000.0    0.077924\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q38:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q38\n",
      "0.0          0.815980\n",
      "100000.0     0.018619\n",
      "200000.0     0.013738\n",
      "50000.0      0.012292\n",
      "1000000.0    0.011931\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q39:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q39\n",
      "0.0        0.741457\n",
      "20000.0    0.051709\n",
      "10000.0    0.040318\n",
      "30000.0    0.038872\n",
      "50000.0    0.029832\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q40:\n",
      "Train NA%: 75.37%\n",
      "Test NA%: 99.03%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q40\n",
      "0.0        0.751085\n",
      "10000.0    0.065618\n",
      "20000.0    0.032357\n",
      "30000.0    0.024946\n",
      "5000.0     0.019704\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q41:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q41\n",
      "60000.0     0.043540\n",
      "50000.0     0.043005\n",
      "70000.0     0.039436\n",
      "100000.0    0.036046\n",
      "40000.0     0.035867\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q42:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q42\n",
      "2.0    0.532477\n",
      "1.0    0.453605\n",
      "3.0    0.013919\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q43:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q43\n",
      "1.0    0.807994\n",
      "2.0    0.192006\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q44:\n",
      "Train NA%: 95.21%\n",
      "Test NA%: 99.85%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q44\n",
      "2.0    0.564126\n",
      "1.0    0.291822\n",
      "3.0    0.105019\n",
      "4.0    0.039033\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q45:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q45\n",
      "1.0    0.570307\n",
      "2.0    0.429693\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q46:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q46\n",
      "2.0    0.745896\n",
      "1.0    0.254104\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q47:\n",
      "Train NA%: 93.64%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q47\n",
      "20000.0    0.167135\n",
      "30000.0    0.160112\n",
      "40000.0    0.078652\n",
      "25000.0    0.064607\n",
      "0.0        0.061798\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q48:\n",
      "Train NA%: 93.64%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q48\n",
      "2.0    0.398876\n",
      "4.0    0.257725\n",
      "3.0    0.188202\n",
      "1.0    0.155197\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q49:\n",
      "Train NA%: 95.28%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q49\n",
      "20000.0    0.163671\n",
      "30000.0    0.123936\n",
      "15000.0    0.102176\n",
      "25000.0    0.076632\n",
      "10000.0    0.054872\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q50:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q50\n",
      "2.0    0.966453\n",
      "1.0    0.033547\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q51:\n",
      "Train NA%: 99.17%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q51\n",
      "1.0    0.691489\n",
      "2.0    0.244681\n",
      "3.0    0.053191\n",
      "4.0    0.010638\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q52:\n",
      "Train NA%: 99.17%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q52\n",
      "3.0    0.558511\n",
      "2.0    0.250000\n",
      "1.0    0.180851\n",
      "4.0    0.010638\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q53:\n",
      "Train NA%: 99.17%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q53\n",
      "2.0    0.776596\n",
      "3.0    0.164894\n",
      "4.0    0.031915\n",
      "1.0    0.021277\n",
      "6.0    0.005319\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q54:\n",
      "Train NA%: 99.17%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q54\n",
      "1.0    0.968085\n",
      "2.0    0.031915\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q55:\n",
      "Train NA%: 99.19%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q55\n",
      "5000.0     0.181319\n",
      "2000.0     0.175824\n",
      "10000.0    0.109890\n",
      "3000.0     0.109890\n",
      "1000.0     0.076923\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q56:\n",
      "Train NA%: 99.19%\n",
      "Test NA%: 99.93%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q56\n",
      "10000.0    0.120879\n",
      "20000.0    0.104396\n",
      "40000.0    0.082418\n",
      "30000.0    0.071429\n",
      "12000.0    0.049451\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q57:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q57\n",
      "2.0    0.951463\n",
      "1.0    0.048537\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q58:\n",
      "Train NA%: 98.79%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q58\n",
      "5000.0     0.316176\n",
      "10000.0    0.198529\n",
      "2000.0     0.180147\n",
      "20000.0    0.080882\n",
      "3000.0     0.066176\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q59:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q59\n",
      "2.0    0.998929\n",
      "1.0    0.001071\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q60:\n",
      "Train NA%: 99.97%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q60\n",
      "2.0    0.500000\n",
      "3.0    0.166667\n",
      "1.0    0.166667\n",
      "0.0    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q61:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q61\n",
      "2.0    0.9702\n",
      "1.0    0.0298\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q62:\n",
      "Train NA%: 99.25%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q62\n",
      "2.0    0.191617\n",
      "5.0    0.185629\n",
      "3.0    0.143713\n",
      "1.0    0.143713\n",
      "7.0    0.071856\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q63:\n",
      "Train NA%: 99.25%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q63\n",
      "8.0     0.359281\n",
      "1.0     0.257485\n",
      "4.0     0.119760\n",
      "2.0     0.095808\n",
      "12.0    0.089820\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q64:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q64\n",
      "2.0    0.98626\n",
      "1.0    0.01374\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q65:\n",
      "Train NA%: 99.66%\n",
      "Test NA%: 100.00%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q65\n",
      "80000.0     0.142857\n",
      "40000.0     0.077922\n",
      "500000.0    0.077922\n",
      "450000.0    0.051948\n",
      "200000.0    0.051948\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Q66:\n",
      "Train NA%: 75.05%\n",
      "Test NA%: 98.95%\n",
      "\n",
      "Value distribution (excluding NAs):\n",
      "Q66\n",
      "4.0    0.312455\n",
      "5.0    0.204497\n",
      "3.0    0.176124\n",
      "2.0    0.165596\n",
      "6.0    0.078158\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First analyze NA distributions across all columns\n",
    "print(\"Initial NA Percentages:\")\n",
    "for col in df.columns:\n",
    "    if col not in ['set', 'subjective_poverty']:  # Skip these metadata columns\n",
    "        train_na = df[df['set'] == 'train'][col].isna().mean()\n",
    "        test_na = df[df['set'] == 'test'][col].isna().mean()\n",
    "        \n",
    "        # Only print if there are any NAs in either set\n",
    "        if train_na > 0 or test_na > 0:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Train NA%: {train_na:.2%}\")\n",
    "            print(f\"Test NA%: {test_na:.2%}\")\n",
    "            \n",
    "            # Also show value distribution for columns with NAs\n",
    "            print(\"\\nValue distribution (excluding NAs):\")\n",
    "            print(df[col].value_counts(normalize=True).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA Percentage Discrepancies (Train vs Test):\n",
      "\n",
      "Column | Train NA% | Test NA% | Difference\n",
      "--------------------------------------------------\n",
      "q13             |   45.27% |   8.02% | 37.25%\n",
      "q14             |   45.27% |   8.02% | 37.25%\n",
      "q19             |   40.83% |   4.12% | 36.71%\n",
      "q20             |   40.83% |   4.12% | 36.71%\n",
      "q07_hh          |   45.78% |  13.19% | 32.59%\n",
      "q08             |   47.51% |  16.79% | 30.72%\n",
      "q21             |   59.94% |  29.84% | 30.11%\n",
      "Q17             |   29.09% |   4.05% | 25.04%\n",
      "Q18             |   29.09% |   4.05% | 25.04%\n",
      "Q19             |   28.93% |   3.97% | 24.96%\n",
      "Q11             |   28.82% |   3.90% | 24.92%\n",
      "Q15             |   74.90% |  98.88% | 23.98%\n",
      "Q21             |   75.05% |  98.95% | 23.90%\n",
      "Q22             |   75.05% |  98.95% | 23.90%\n",
      "Q23             |   75.05% |  98.95% | 23.90%\n",
      "Q24             |   75.05% |  98.95% | 23.90%\n",
      "Q41             |   75.05% |  98.95% | 23.90%\n",
      "Q42             |   75.05% |  98.95% | 23.90%\n",
      "Q43             |   75.05% |  98.95% | 23.90%\n",
      "Q45             |   75.05% |  98.95% | 23.90%\n",
      "Q46             |   75.05% |  98.95% | 23.90%\n",
      "Q50             |   75.05% |  98.95% | 23.90%\n",
      "Q57             |   75.05% |  98.95% | 23.90%\n",
      "Q59             |   75.05% |  98.95% | 23.90%\n",
      "Q61             |   75.05% |  98.95% | 23.90%\n",
      "Q64             |   75.05% |  98.95% | 23.90%\n",
      "Q66             |   75.05% |  98.95% | 23.90%\n",
      "Q09             |   75.16% |  99.03% | 23.86%\n",
      "Q12             |   75.34% |  99.18% | 23.84%\n",
      "Q13             |   75.34% |  99.18% | 23.84%\n",
      "Q26             |   75.11% |  98.95% | 23.84%\n",
      "Q27             |   75.11% |  98.95% | 23.84%\n",
      "Q28             |   75.11% |  98.95% | 23.84%\n",
      "Q32             |   75.11% |  98.95% | 23.84%\n",
      "Q33             |   75.37% |  99.03% | 23.66%\n",
      "Q34             |   75.37% |  99.03% | 23.66%\n",
      "Q35             |   75.37% |  99.03% | 23.66%\n",
      "Q38             |   75.37% |  99.03% | 23.66%\n",
      "Q40             |   75.37% |  99.03% | 23.66%\n",
      "Q37             |   75.37% |  99.03% | 23.65%\n",
      "Q39             |   75.37% |  99.03% | 23.65%\n",
      "Q36             |   75.38% |  99.03% | 23.65%\n",
      "q15             |   71.52% |  48.35% | 23.17%\n",
      "q16             |   73.75% |  59.67% | 14.08%\n",
      "q06_hh          |    8.66% |   0.00% | 8.66%\n",
      "q22             |   80.88% |  74.29% | 6.60%\n",
      "Q47             |   93.64% | 100.00% | 6.36%\n",
      "Q48             |   93.64% | 100.00% | 6.36%\n",
      "Q29             |   94.53% |  99.55% | 5.02%\n",
      "Q30             |   94.53% |  99.55% | 5.02%\n",
      "Q49             |   95.28% | 100.00% | 4.72%\n",
      "Q44             |   95.21% |  99.85% | 4.64%\n",
      "Q25             |   95.18% |  99.55% | 4.37%\n",
      "Q20             |   96.55% |  99.85% | 3.30%\n",
      "Q58             |   98.79% | 100.00% | 1.21%\n",
      "q04             |    3.99% |   2.92% | 1.06%\n",
      "q05             |    3.99% |   2.92% | 1.06%\n",
      "q06             |    3.99% |   2.92% | 1.06%\n",
      "q07             |    3.99% |   2.92% | 1.06%\n",
      "Q08             |    3.99% |   2.92% | 1.06%\n",
      "Q14             |    3.99% |   2.92% | 1.06%\n",
      "Q51             |   99.17% |  99.93% | 0.76%\n",
      "Q52             |   99.17% |  99.93% | 0.76%\n",
      "Q53             |   99.17% |  99.93% | 0.76%\n",
      "Q54             |   99.17% |  99.93% | 0.76%\n",
      "Q62             |   99.25% | 100.00% | 0.75%\n",
      "Q63             |   99.25% | 100.00% | 0.75%\n",
      "Q55             |   99.19% |  99.93% | 0.73%\n",
      "Q56             |   99.19% |  99.93% | 0.73%\n",
      "Q65             |   99.66% | 100.00% | 0.34%\n",
      "Q31             |   99.88% | 100.00% | 0.12%\n",
      "Q16             |   99.84% |  99.93% | 0.08%\n",
      "Q60             |   99.97% | 100.00% | 0.03%\n",
      "Q10             |   99.83% |  99.85% | 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Calculate NA percentage differences between train and test sets\n",
    "na_differences = {}\n",
    "for col in df.columns:\n",
    "    if col not in ['set', 'subjective_poverty']:\n",
    "        train_na = df[df['set'] == 'train'][col].isna().mean()\n",
    "        test_na = df[df['set'] == 'test'][col].isna().mean()\n",
    "        difference = abs(train_na - test_na)\n",
    "        \n",
    "        if difference > 0:  # Only store columns with differences\n",
    "            na_differences[col] = {\n",
    "                'difference': difference,\n",
    "                'train_na': train_na,\n",
    "                'test_na': test_na\n",
    "            }\n",
    "\n",
    "# Sort and display columns by discrepancy\n",
    "sorted_differences = sorted(na_differences.items(), \n",
    "                          key=lambda x: x[1]['difference'], \n",
    "                          reverse=True)\n",
    "\n",
    "print(\"NA Percentage Discrepancies (Train vs Test):\")\n",
    "print(\"\\nColumn | Train NA% | Test NA% | Difference\")\n",
    "print(\"-\" * 50)\n",
    "for col, stats in sorted_differences:\n",
    "    print(f\"{col:15} | {stats['train_na']:8.2%} | {stats['test_na']:7.2%} | {stats['difference']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLf0sCIh4Khs"
   },
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 9176,
     "status": "ok",
     "timestamp": 1731982504020,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "hrfiN4ZF4NfK",
    "outputId": "5180ee42-3874-4803-803b-8b9d037b0911"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_primary'] = row['q05']\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_primary'] = 9\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_secondary'] = 3\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_uni'] = row['q05']\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_primary'] = 9\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_secondary'] = row['q05']\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_primary'] = 9\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_secondary'] = 3\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_vocational'] = row['q05']\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_primary'] = 9\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_secondary'] = 3\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_54776/961380015.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[i]['years_uni'] = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "2    4957\n",
      "6    4038\n",
      "5    3555\n",
      "4    3548\n",
      "1    2915\n",
      "3    2786\n",
      "0    1941\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# turn q24_ed (distance from school) into categorical\\ndef distance_category(dist):\\n  if dist == 0:\\n    return 0\\n  if dist < 1:\\n    return 1\\n  if dist < 2:\\n    return 2\\n  if dist < 3:\\n    return 3\\n  if dist < 4:\\n    return 4\\n  if dist < 5:\\n    return 5\\n  if dist < 10:\\n    return 6\\n  if dist < 50:\\n    return 7\\n  if dist < 100:\\n    return 8\\n  return 9\\n\\ndf['dist_from_school'] = [distance_category(dist) for dist in df['Q24']]\\ndf.drop(columns=['Q24'], inplace=True)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['highest_ed'] = [highest_education(ind) for ind, row in df.iterrows()]\n",
    "#df.drop(columns=['q04', 'q05'], inplace=True)\n",
    "\n",
    "# Replace Q05\n",
    "df['years_primary'] = 0\n",
    "df['years_secondary'] = 0\n",
    "df['years_vocational'] = 0\n",
    "df['years_uni'] = 0\n",
    "df['years_postgrad'] = 0\n",
    "for i, row in df.iterrows():\n",
    "  if row['q03'] == 2:\n",
    "      continue\n",
    "  if row['q04'] == 1:\n",
    "    df.loc[i]['years_primary'] = row['q05']\n",
    "  elif row['q04'] == 2:\n",
    "    df.loc[i]['years_primary'] = 9\n",
    "    df.loc[i]['years_secondary'] = row['q05']\n",
    "  elif row['q04'] in [3,4,5]:\n",
    "    df.loc[i]['years_primary'] = 9\n",
    "    df.loc[i]['years_secondary'] = 3\n",
    "    df.loc[i]['years_vocational'] = row['q05']\n",
    "  elif row['q04'] in [6,7]:\n",
    "    df.loc[i]['years_primary'] = 9\n",
    "    df.loc[i]['years_secondary'] = 3\n",
    "    df.loc[i]['years_uni'] = row['q05']\n",
    "  else:\n",
    "    df['years_postgrad'] = row['q05']\n",
    "    df.loc[i]['years_primary'] = 9\n",
    "    df.loc[i]['years_secondary'] = 3\n",
    "    df.loc[i]['years_uni'] = 4\n",
    "df.drop(columns=['q05'], inplace=True)\n",
    "#df.drop(columns=['q05', 'Q13', 'Q22'], inplace=True)\n",
    "\n",
    "# Combine postsecondary for q4\n",
    "#df['q04'] = [min(row['q04'], 6.0) for i,row in df.iterrows()]\n",
    "# ^ TRY WITHOUT THIS ERR(1)\n",
    "\n",
    "# combine age (year and month) into single number\n",
    "# Note: Maybe change this to categorical for logistic regression? Seems unlikely\n",
    "#       to be linear\n",
    "df['age'] = df['q05y'] + df['q05m'] / 12\n",
    "df.drop(columns=['q05y', 'q05m'], inplace=True)\n",
    "def age_group(age):\n",
    "    if (age < 12):\n",
    "        return 0\n",
    "    elif (age < 18):\n",
    "        return 1\n",
    "    elif (age < 30):\n",
    "        return 2\n",
    "    elif (age < 40):\n",
    "        return 3\n",
    "    elif (age < 50):\n",
    "        return 4\n",
    "    elif (age < 60):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "df['age_group'] = [age_group(age) for age in df['age']]\n",
    "#df.drop(columns=['age'], inplace=True)\n",
    "\n",
    "print(df['age_group'].value_counts())\n",
    "\n",
    "# following commented out because we removed the q24 column\n",
    "\n",
    "\"\"\"\n",
    "# turn q24_ed (distance from school) into categorical\n",
    "def distance_category(dist):\n",
    "  if dist == 0:\n",
    "    return 0\n",
    "  if dist < 1:\n",
    "    return 1\n",
    "  if dist < 2:\n",
    "    return 2\n",
    "  if dist < 3:\n",
    "    return 3\n",
    "  if dist < 4:\n",
    "    return 4\n",
    "  if dist < 5:\n",
    "    return 5\n",
    "  if dist < 10:\n",
    "    return 6\n",
    "  if dist < 50:\n",
    "    return 7\n",
    "  if dist < 100:\n",
    "    return 8\n",
    "  return 9\n",
    "\n",
    "df['dist_from_school'] = [distance_category(dist) for dist in df['Q24']]\n",
    "df.drop(columns=['Q24'], inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQf_B1MtddVv"
   },
   "source": [
    "One hot encoding for categorical variables + cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1731982504247,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "motctahedjKZ"
   },
   "outputs": [],
   "source": [
    "categorical = ['q01', 'q02', 'q06','Q11', 'Q17','q03_hh', 'q06_hh', 'q13', 'q19',\n",
    "               'age_group', 'psu']#'highest_ed']\n",
    "\n",
    "# following commented out because we removed most columns\n",
    "\"\"\"categorical = ['q04', 'q06', 'Q10', 'Q11', 'Q12', 'Q16', 'Q17',\n",
    "               'Q21', 'Q23', 'Q28', 'Q42', 'Q44', 'Q48', 'Q52',\n",
    "               'Q53', 'Q63', 'Q66', 'q03_hh', 'q06_hh', 'q13', 'q19',\n",
    "               'dist_from_school']\n",
    "\"\"\"\n",
    "\n",
    "# create onehot df and add it to the original df\n",
    "for col in categorical:\n",
    "    new_onehot = pd.get_dummies(df[col], prefix = col)\n",
    "    df = pd.concat([df, new_onehot],axis=1)\n",
    "\n",
    "# drop the original categorical\n",
    "df.drop(columns=categorical, inplace=True)\n",
    "\n",
    "# useless columns (q04_hh is date of birth, redundant with q05 which is age)\n",
    "# hhid would be useful, but no observations in the train and test set share a hhid\n",
    "df.drop(columns=['q04_hh', 'hhid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making parent age death categorical\n",
    "\n",
    "# First modify the parent age categorization to use string labels instead of numbers\n",
    "def categorize_parent_age(is_alive, age):\n",
    "    if pd.isna(age):\n",
    "        if is_alive == 1:  \n",
    "            return 'alive'\n",
    "        else:  \n",
    "            return 'deceased_unknown'\n",
    "    else:  \n",
    "        if age < 40:\n",
    "            return 'died_under_40'\n",
    "        elif age < 50:\n",
    "            return 'died_40_50'\n",
    "        elif age < 60:\n",
    "            return 'died_50_60'\n",
    "        elif age < 70:\n",
    "            return 'died_60_70'\n",
    "        else:\n",
    "            return 'died_over_70'\n",
    "\n",
    "# Apply categorization\n",
    "df['mother_status'] = df.apply(\n",
    "    lambda row: categorize_parent_age(\n",
    "        row['q14'] if 'q14' in row else row['q11'],\n",
    "        row['q15']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "df['father_status'] = df.apply(\n",
    "    lambda row: categorize_parent_age(\n",
    "        row['q20'] if 'q20' in row else row['q17'],\n",
    "        row['q21']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# One-hot encode the new categorical columns\n",
    "mother_dummies = pd.get_dummies(df['mother_status'], prefix='mother')\n",
    "father_dummies = pd.get_dummies(df['father_status'], prefix='father')\n",
    "\n",
    "# Add the dummy columns to the dataframe and drop the original columns\n",
    "df = pd.concat([df, mother_dummies, father_dummies], axis=1)\n",
    "df.drop(columns=['mother_status', 'father_status', 'q15', 'q21'], inplace=True)\n",
    "\n",
    "# Print value distributions to verify\n",
    "#print(\"\\nMother age category distribution:\")\n",
    "#print(df['q15'].value_counts(normalize=True))\n",
    "#print(\"\\nFather age category distribution:\")\n",
    "#print(df['q21'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eax9IGzkduG2"
   },
   "source": [
    "Normalization + train test split + filling in remaining NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For real test set:\n",
    "df_train = df.join(y_train, how='inner').sample(frac=1)\n",
    "df_test = df[df['set'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1731982506637,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "Btbnh2lzdwKe",
    "outputId": "761717db-4dba-4f72-cbc4-8748ab996a6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_29153/2212852605.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[col] = (df_test[col] - means[col]) / stds[col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all same q10\n",
      "all same Q10\n",
      "all same Q15\n",
      "all same Q20\n",
      "all same Q23\n",
      "all same Q30\n",
      "all same Q46\n",
      "all same Q57\n",
      "all same Q59\n",
      "all same Q61\n",
      "all same Q64\n",
      "all same years_primary\n",
      "all same years_secondary\n",
      "all same years_vocational\n",
      "all same years_uni\n",
      "all same years_postgrad\n",
      "all same q06_8.0\n",
      "all same Q11_5.0\n",
      "all same Q11_7.0\n",
      "all same Q11_9.0\n",
      "all same Q11_11.0\n",
      "all same Q17_5.0\n",
      "all same Q17_6.0\n",
      "all same Q17_9.0\n",
      "all same Q17_11.0\n",
      "all same q03_hh_5\n",
      "all same q03_hh_6\n",
      "all same q03_hh_8\n",
      "all same q03_hh_10\n",
      "all same q03_hh_11\n",
      "all same q03_hh_12\n",
      "all same q03_hh_13\n",
      "all same q03_hh_14\n",
      "all same q06_hh_3.0\n",
      "all same age_group_0\n",
      "all same psu_4\n",
      "all same psu_6\n",
      "all same psu_8\n",
      "all same psu_11\n",
      "all same psu_14\n",
      "all same psu_22\n",
      "all same psu_23\n",
      "all same psu_27\n",
      "all same psu_34\n",
      "all same psu_35\n",
      "all same psu_37\n",
      "all same psu_39\n",
      "all same psu_40\n",
      "all same psu_54\n",
      "all same psu_55\n",
      "all same psu_56\n",
      "all same psu_58\n",
      "all same psu_61\n",
      "all same psu_67\n",
      "all same psu_69\n",
      "all same psu_74\n",
      "all same psu_79\n",
      "all same psu_82\n",
      "all same psu_86\n",
      "all same psu_94\n",
      "all same psu_98\n",
      "all same psu_111\n",
      "all same psu_114\n",
      "all same psu_126\n",
      "all same psu_130\n",
      "all same psu_132\n",
      "all same psu_137\n",
      "all same psu_138\n",
      "all same psu_139\n",
      "all same psu_142\n",
      "all same psu_148\n",
      "all same psu_150\n",
      "all same psu_154\n",
      "all same psu_155\n",
      "all same psu_173\n",
      "all same psu_176\n",
      "all same psu_178\n",
      "all same psu_179\n",
      "all same psu_180\n",
      "all same psu_182\n",
      "all same psu_189\n",
      "all same psu_194\n",
      "all same psu_195\n",
      "all same psu_196\n",
      "all same psu_202\n",
      "all same psu_218\n",
      "all same psu_219\n",
      "all same psu_222\n",
      "all same psu_223\n",
      "all same psu_224\n",
      "all same psu_235\n",
      "all same psu_243\n",
      "all same psu_252\n",
      "all same psu_262\n",
      "all same psu_263\n",
      "all same psu_272\n",
      "all same psu_279\n",
      "all same psu_282\n",
      "all same psu_289\n",
      "all same psu_290\n",
      "all same psu_295\n",
      "all same psu_301\n",
      "all same psu_302\n",
      "all same psu_303\n",
      "all same psu_309\n",
      "all same psu_317\n",
      "all same psu_323\n",
      "all same psu_326\n",
      "all same psu_332\n",
      "all same psu_334\n",
      "all same psu_361\n",
      "all same psu_374\n",
      "all same psu_381\n",
      "all same psu_392\n",
      "all same psu_396\n",
      "all same psu_421\n",
      "all same psu_426\n",
      "all same psu_427\n",
      "all same psu_429\n",
      "all same psu_443\n",
      "all same psu_452\n",
      "all same psu_453\n",
      "all same psu_457\n",
      "all same psu_458\n",
      "all same psu_459\n",
      "all same psu_461\n",
      "all same psu_474\n",
      "all same psu_476\n",
      "all same psu_480\n",
      "all same psu_483\n",
      "all same psu_489\n",
      "all same psu_492\n",
      "all same psu_493\n",
      "all same psu_507\n",
      "all same psu_510\n",
      "all same psu_539\n",
      "all same psu_545\n",
      "all same psu_547\n",
      "all same psu_550\n",
      "all same psu_551\n",
      "all same psu_556\n",
      "all same psu_564\n",
      "all same psu_576\n",
      "all same psu_587\n",
      "all same psu_589\n",
      "all same psu_597\n",
      "all same psu_604\n",
      "all same psu_611\n",
      "all same psu_618\n",
      "all same psu_620\n",
      "all same psu_624\n",
      "all same psu_627\n",
      "all same psu_645\n",
      "all same psu_671\n",
      "all same psu_683\n",
      "all same psu_685\n",
      "all same psu_694\n",
      "all same psu_708\n",
      "all same psu_709\n",
      "all same psu_714\n",
      "all same psu_729\n",
      "all same psu_745\n",
      "all same psu_754\n",
      "all same psu_758\n",
      "all same psu_766\n",
      "all same psu_770\n",
      "all same psu_782\n",
      "all same psu_786\n",
      "all same psu_798\n",
      "all same psu_809\n",
      "all same psu_815\n",
      "all same psu_821\n",
      "all same psu_834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_29153/2212852605.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(columns=same_cols, inplace=True)\n",
      "/var/folders/2r/86pfjpys1k771ybrfsqxg_8m0000gn/T/ipykernel_29153/2212852605.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "same_cols = []\n",
    "\n",
    "means = {}\n",
    "stds = {}\n",
    "\n",
    "# standardization\n",
    "for col in df_train:\n",
    "    if col not in ['psu_hh_idcode', 'subjective_poverty', 'set'] :\n",
    "        if df_train[col].std() == 0 or df_test[col].std() == 0:\n",
    "            print(\"all same\", col)\n",
    "            same_cols.append(col)\n",
    "            continue\n",
    "        means[col] = df_train[col].mean()\n",
    "        stds[col] = df_train[col].std()\n",
    "        df_train[col] = (df_train[col] - means[col]) / stds[col]\n",
    "        df_test[col] = (df_test[col] - means[col]) / stds[col]\n",
    "\n",
    "# drop columns that are all the same (i.e. give no info) in train or test set\n",
    "df_train.drop(columns=same_cols, inplace=True)\n",
    "df_test.drop(columns=same_cols, inplace=True)\n",
    "\n",
    "# fill remaining NAs with 0 (i.e. mean)\n",
    "# maybe change this part to be smarter\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz8e49eSeLfA"
   },
   "source": [
    "Fit + eval for logistic regression, KNN, random forest, boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1731982507931,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "D2VCbqYteOIX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "def smooth(p):\n",
    "    # Ensure the probabilities sum to 1\n",
    "    p = p / np.sum(p)\n",
    "\n",
    "    # Identify the index and value of the maximum probability\n",
    "    max_idx = np.argmax(p)\n",
    "    p_max = p[max_idx]\n",
    "\n",
    "    # Set K as (N / 2) squared, where N is the length of p\n",
    "    N = len(p)\n",
    "    K = (N / 2) ** 2\n",
    "\n",
    "    # Compute sigma_squared based on the maximum probability\n",
    "    sigma_squared = K * (1 - p_max)\n",
    "\n",
    "    # If sigma_squared is zero, no smoothing is needed\n",
    "    if sigma_squared == 0:\n",
    "        return p  # Return the original probabilities\n",
    "\n",
    "    # Compute Gaussian weights centered at max_idx\n",
    "    indices = np.arange(N)\n",
    "    gaussian_weights = np.exp(-((indices - max_idx) ** 2) / (2 * sigma_squared))\n",
    "\n",
    "    # Apply the Gaussian weights to the probabilities\n",
    "    p_new = p * gaussian_weights\n",
    "\n",
    "    # Normalize the new probabilities so they sum to 1\n",
    "    p_new /= np.sum(p_new)\n",
    "\n",
    "    return p_new\n",
    "\n",
    "for idx, item in df_train.iterrows():\n",
    "  if item[\"set\"] == \"test\":\n",
    "    print(\"misrepresented\")\n",
    "\n",
    "X = df_train.drop(columns=[\"subjective_poverty\", \"set\"])\n",
    "y = df_train[\"subjective_poverty\"]\n",
    "\n",
    "# actual test set\n",
    "X_test = df_test.drop(columns=[\"set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations in X: 5334\n",
      "For each fold in 5-fold cross validation:\n",
      "Training set size: 4267 observations\n",
      "Testing set size: 1067 observations\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total observations in X: {len(X)}\")\n",
    "train_size = int(len(X) * 0.8)  # 80% for training\n",
    "test_size = len(X) - train_size  # 20% for testing\n",
    "\n",
    "print(f\"For each fold in 5-fold cross validation:\")\n",
    "print(f\"Training set size: {train_size} observations\")\n",
    "print(f\"Testing set size: {test_size} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 13319,
     "status": "ok",
     "timestamp": 1731982521249,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "njUmLcdeA6Fj"
   },
   "outputs": [],
   "source": [
    "# First fit the model\n",
    "lr = linear_model.LogisticRegressionCV(\n",
    "    cv=5,\n",
    "    penalty='l2',\n",
    "    scoring='neg_log_loss',\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Get the mean scores and standard errors\n",
    "mean_scores = -np.mean(lr.scores_[list(lr.scores_.keys())[0]], axis=0)  # Negative because we used neg_log_loss\n",
    "std_scores = np.std(lr.scores_[list(lr.scores_.keys())[0]], axis=0)\n",
    "\n",
    "# Find the minimum score and its index\n",
    "min_score_idx = np.argmin(mean_scores)\n",
    "min_score = mean_scores[min_score_idx]\n",
    "\n",
    "# Find the largest C value whose score is within one std err of the minimum\n",
    "threshold = min_score + std_scores[min_score_idx]\n",
    "valid_indices = np.where(mean_scores <= threshold)[0]\n",
    "one_se_idx = valid_indices[0]  # Take the largest C value (first index due to C being in descending order)\n",
    "optimal_c = lr.C_[one_se_idx]\n",
    "\n",
    "# Refit with the one-SE C value\n",
    "lr_final = linear_model.LogisticRegression(\n",
    "    C=optimal_c,\n",
    "    penalty='l2',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "probs_lr = lr_final.fit(X,y).predict_proba(X_test)\n",
    "probs_lr_smooth = [smooth(i) for i in probs_lr]\n",
    "\n",
    "\n",
    "#development test set\n",
    "#print(metrics.log_loss(y_test, probs_lr, labels = ['subjective_poverty_' + str(i) for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_lr_smooth, labels = ['subjective_poverty_' + str(i) for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#development test set\n",
    "#print(metrics.log_loss(y_test, probs_lr, labels = [i for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_lr_smooth, labels = [i for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1731982609114,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "71eE7R2x8k9A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal k: 441\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find optimal k using cross-validation\n",
    "k_range = range(1, 501, 10)  # Test k values from 1 to 500 in steps of 10\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    scores = model_selection.cross_val_score(knn, X, y, cv=5, scoring='neg_log_loss')\n",
    "    cv_scores.append(-scores.mean())  # Negative because we want to minimize log loss\n",
    "\n",
    "# Find the optimal k\n",
    "optimal_k = k_range[np.argmin(cv_scores)]\n",
    "\n",
    "# Train final model with optimal k\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "probs_knn = knn.fit(X,y).predict_proba(X_test)\n",
    "\n",
    "probs_knn_smooth = [smooth(i) for i in probs_knn]\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal k: {optimal_k}\")\n",
    "#print(f\"Log loss (unsmoothed): {metrics.log_loss(y_test, probs_knn)}\")\n",
    "#print(f\"Log loss (smoothed): {metrics.log_loss(y_test, probs_knn_smooth)}\")\n",
    "\n",
    "# Optionally plot CV results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, cv_scores)\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Cross-Validation Log Loss')\n",
    "plt.title('KNN Cross-Validation Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics.log_loss(y_test, probs_knn, labels = [i for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_knn_smooth, labels = [i for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7384,
     "status": "ok",
     "timestamp": 1731982616497,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "kDaa2KqxnkHt"
   },
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(random_state=42, criterion=\"log_loss\")\n",
    "probs_rf = rf.fit(X,y).predict_proba(X_test)\n",
    "probs_rf_smooth = [smooth(i) for i in probs_rf]\n",
    "#print(metrics.log_loss(y_test, probs_rf, labels = [i for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_rf_smooth, labels = [i for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create RandomForest with CV\n",
    "rf_cv = model_selection.GridSearchCV(\n",
    "    ensemble.RandomForestClassifier(random_state=42, criterion=\"log_loss\"),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_log_loss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and predict\n",
    "rf_cv.fit(X, y)\n",
    "probs_rf = rf_cv.predict_proba(X_test)\n",
    "probs_rf_smooth = [smooth(i) for i in probs_rf]\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters:\", rf_cv.best_params_)\n",
    "#print(\"Best CV score:\", -rf_cv.best_score_)  # Negative because of neg_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 61205,
     "status": "ok",
     "timestamp": 1731982677700,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "Au59pf9_nlgq"
   },
   "outputs": [],
   "source": [
    "gb = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "probs_gb = gb.fit(X,y).predict_proba(X_test)\n",
    "probs_gb_smooth = [smooth(i) for i in probs_gb]\n",
    "\n",
    "# development test set\n",
    "#print(metrics.log_loss(y_test, probs_gb, labels = ['subjective_poverty_' + str(i) for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_gb_smooth, labels = ['subjective_poverty_' + str(i) for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Adjust the labels to be 0-based\n",
    "y_zero_based = y - 1  # Subtract 1 from all labels to make them 0-based\n",
    "\n",
    "# Parameter distributions (unchanged)\n",
    "#param_distributions = {\n",
    "#       'learning_rate': uniform(0.01, 0.3),\n",
    "#    'max_depth': randint(3, 10),\n",
    "#    'n_estimators': randint(100, 1000),\n",
    "#    'reg_alpha': uniform(0, 2),\n",
    "#    'reg_lambda': uniform(0, 2),\n",
    "#    'gamma': uniform(0, 5),\n",
    "#    'subsample': uniform(0.6, 0.4),\n",
    "#    'colsample_bytree': uniform(0.6, 0.4),\n",
    "#    'colsample_bylevel': uniform(0.6, 0.4),\n",
    "#    'min_child_weight': randint(1, 7),\n",
    "#    'max_delta_step': randint(0, 10),\n",
    "#    'scale_pos_weight': uniform(0.8, 0.4)\n",
    "#}\n",
    "\n",
    "#NEW\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0.005, 0.095),  # Lower learning rates\n",
    "    'max_depth': randint(3, 7),  # Reduced max depth range\n",
    "    'n_estimators': randint(200, 2000),  # More estimators\n",
    "    'reg_alpha': uniform(0.1, 1.9),  # L1 regularization\n",
    "    'reg_lambda': uniform(0.1, 1.9),  # L2 regularization\n",
    "    'gamma': uniform(0.1, 0.9),  # Minimum loss reduction\n",
    "    'subsample': uniform(0.7, 0.3),  # Slightly higher subsample\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'min_child_weight': randint(3, 7),  # Increased min_child_weight\n",
    "}\n",
    "\n",
    "# Base model with adjusted num_class\n",
    "xgb_base = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=10,  # Still 10 classes, but now 0-9\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    grow_policy='lossguide'\n",
    ")\n",
    "\n",
    "# Random Search with adjusted y values\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    scoring='neg_log_loss',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    #random_state=42\n",
    ")\n",
    "\n",
    "# Fit with adjusted y values\n",
    "random_search.fit(X, y_zero_based)\n",
    "\n",
    "# When making predictions, add 1 back to get original scale\n",
    "probs_xgb = random_search.predict_proba(X_test)\n",
    "probs_xgb_smooth = [smooth(i) for i in probs_xgb]\n",
    "\n",
    "# Evaluate using original 1-10 labels\n",
    "#print(\"\\nFinal model performance:\")\n",
    "#print(f\"Log loss (unsmoothed): {metrics.log_loss(y_test, probs_xgb, labels=[i for i in range(1,11)])}\")\n",
    "#print(f\"Log loss (smoothed): {metrics.log_loss(y_test, probs_xgb_smooth, labels=[i for i in range(1,11)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development test set\n",
    "#print(metrics.log_loss(y_test, probs_gb, labels = [i for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_gb_smooth, labels = [i for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 835244,
     "status": "ok",
     "timestamp": 1731983512937,
     "user": {
      "displayName": "Kevin Li",
      "userId": "02362265452529969860"
     },
     "user_tz": 300
    },
    "id": "FPnfYe3SBeTl",
    "outputId": "df570e31-89e0-426c-bd8f-17d4a5988481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n"
     ]
    }
   ],
   "source": [
    "stack = ensemble.StackingClassifier([('logistic CV', lr_final), ('knn', knn), (\"XGboost\", random_search.best_estimator_)])\n",
    "stack_fit = stack.fit(X,y)\n",
    "probs_stack = stack_fit.predict_proba(X_test)\n",
    "probs_stack_smooth = [smooth(i) for i in probs_stack]\n",
    "\n",
    "# development test set\n",
    "#print(metrics.log_loss(y_test, probs_stack, labels = [i for i in range(1,11)]))\n",
    "#print(metrics.log_loss(y_test, probs_stack_smooth, labels = [i for i in range(1,11)]))\n",
    "\n",
    "#real test set\n",
    "out_df = pd.DataFrame(index=df_test.index, columns = ['subjective_poverty_' + str(i) for i in range(1,11)], data=probs_stack)\n",
    "\n",
    "print(len(out_df))\n",
    "out_df.to_csv(\"probs_4.csv\") # best one is logistic CV, knn, XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.74956716 -1.75252509 -1.7474914  -1.77125678 -1.75074781]\n"
     ]
    }
   ],
   "source": [
    "stack = ensemble.StackingClassifier([('logistic CV', lr_final), ('knn', knn), ('XGboost',random_search.best_estimator_)])\n",
    "scores = model_selection.cross_val_score(stack, X, y, cv=5, scoring='neg_log_loss', n_jobs=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7545185329638453\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack_fit.classes_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
